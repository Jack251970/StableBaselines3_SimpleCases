{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T10:56:23.328906Z",
     "start_time": "2025-06-30T10:56:23.195872Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "#自定义一个Wrapper\n",
    "class Pendulum(gym.Wrapper):\n",
    "\n",
    "    def __init__(self):\n",
    "        env = gym.make('Pendulum-v1')\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        state, info = self.env.reset()\n",
    "        return state, info\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, done, truncated, info = self.env.step(action)\n",
    "        return state, reward, done, truncated, info\n",
    "\n",
    "\n",
    "Pendulum().reset()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.997827  , 0.06588829, 0.38405415], dtype=float32), {})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-06-30T10:57:40.033369Z",
     "start_time": "2025-06-30T10:57:40.014124Z"
    }
   },
   "source": [
    "#测试一个环境\n",
    "def test(env, wrap_action_in_list=False):\n",
    "    print(env)\n",
    "\n",
    "    state = env.reset()\n",
    "    over = False\n",
    "    step = 0\n",
    "\n",
    "    while not over:\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        if wrap_action_in_list:\n",
    "            action = [action]\n",
    "\n",
    "        next_state, reward, over, _, _ = env.step(action)\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(step, state, action, reward)\n",
    "\n",
    "        if step > 200:\n",
    "            break\n",
    "\n",
    "        state = next_state\n",
    "        step += 1\n",
    "\n",
    "\n",
    "test(Pendulum())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Pendulum<TimeLimit<OrderEnforcing<PassiveEnvChecker<PendulumEnv<Pendulum-v1>>>>>>\n",
      "0 (array([-0.4691058 , -0.883142  , -0.20973344], dtype=float32), {}) [-1.1045635] -4.245405942066593\n",
      "20 [-0.4018474   0.91570663  1.414736  ] [-0.2861242] -4.13779416845475\n",
      "40 [-0.63657784 -0.77121246 -3.7317877 ] [0.6696638] -6.504510714284118\n",
      "60 [-0.83991814  0.5427131   4.2385383 ] [-1.2615361] -8.392370163169778\n",
      "80 [-0.9989467   0.04588455 -5.5532975 ] [-1.5991619] -12.669777657641209\n",
      "100 [-0.9768472  -0.21393828  5.9013104 ] [0.34193948] -12.04406833734451\n",
      "120 [-0.9576539   0.28792185 -5.8473873 ] [-1.132296] -11.540334657338475\n",
      "140 [-0.97199184 -0.23501462  6.2311244 ] [-0.5069268] -12.318249651150294\n",
      "160 [-0.7329268 -0.6803075 -6.091003 ] [-1.8259742] -9.441779788987565\n",
      "180 [ 0.99605465 -0.08874175 -1.3733063 ] [-0.77021796] -0.19708609086447199\n",
      "200 [ 0.36763787  0.929969   -4.718802  ] [-1.8153288] -3.6564252435145272\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eb2U4_K6SNUx",
    "ExecuteTime": {
     "end_time": "2025-06-30T11:01:55.933742Z",
     "start_time": "2025-06-30T11:01:55.918949Z"
    }
   },
   "source": [
    "#修改最大步数\n",
    "class StepLimitWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.current_step = 0\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.current_step = 0\n",
    "        return self.env.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        state, reward, done, truncated, info  = self.env.step(action)\n",
    "\n",
    "        #修改done字段\n",
    "        if self.current_step >= 100:\n",
    "            done = True\n",
    "\n",
    "        return state, reward, done, truncated, info\n",
    "\n",
    "\n",
    "test(StepLimitWrapper(Pendulum()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StepLimitWrapper<Pendulum<TimeLimit<OrderEnforcing<PassiveEnvChecker<PendulumEnv<Pendulum-v1>>>>>>>\n",
      "0 (array([-0.09608521,  0.99537313,  0.2529563 ], dtype=float32), {}) [1.6271371] -2.788035294230727\n",
      "20 [ 0.31086937 -0.9504526  -1.1583184 ] [-1.3020552] -1.7101093517205692\n",
      "40 [ 0.54534     0.83821493 -0.27485672] [-1.5568552] -0.9980177151085119\n",
      "60 [ 0.62841   -0.7778823  3.09197  ] [-0.92350626] -1.751276482180738\n",
      "80 [-0.9394501   0.34268573 -7.9643903 ] [1.7432866] -14.140440238265683\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5E6kZfzW8vy",
    "ExecuteTime": {
     "end_time": "2025-06-30T11:02:46.607636Z",
     "start_time": "2025-06-30T11:02:46.588639Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "#修改动作空间\n",
    "class NormalizeActionWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self, env):\n",
    "        #获取动作空间\n",
    "        action_space = env.action_space\n",
    "\n",
    "        #动作空间必须是连续值\n",
    "        assert isinstance(action_space, gym.spaces.Box)\n",
    "\n",
    "        #重新定义动作空间,在正负一之间的连续值\n",
    "        #这里其实只影响env.action_space.sample的返回结果\n",
    "        #实际在计算时,还是正负2之间计算的\n",
    "        env.action_space = gym.spaces.Box(low=-1,\n",
    "                                          high=1,\n",
    "                                          shape=action_space.shape,\n",
    "                                          dtype=np.float32)\n",
    "\n",
    "        super().__init__(env)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        return self.env.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        #重新缩放动作的值域\n",
    "        action = action * 2.0\n",
    "\n",
    "        if action > 2.0:\n",
    "            action = 2.0\n",
    "\n",
    "        if action < -2.0:\n",
    "            action = -2.0\n",
    "\n",
    "        return self.env.step(action)\n",
    "\n",
    "\n",
    "test(NormalizeActionWrapper(Pendulum()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NormalizeActionWrapper<Pendulum<TimeLimit<OrderEnforcing<PassiveEnvChecker<PendulumEnv<Pendulum-v1>>>>>>>\n",
      "0 (array([0.8683225 , 0.49600008, 0.26862347], dtype=float32), {}) [0.15149884] -0.27665433265454015\n",
      "20 [ 0.2755823 -0.9612775  4.7309628] [0.7567814] -3.908724785659091\n",
      "40 [ 0.823339  -0.5675499 -1.5734091] [0.04376562] -0.6118140816421935\n",
      "60 [ 0.6945427  0.7194515 -2.340134 ] [-0.47278035] -1.1933454085510684\n",
      "80 [-0.94381416  0.3304767   7.1183777 ] [-0.54940784] -12.935150975053574\n",
      "100 [ 0.8611308 -0.5083835 -1.381999 ] [0.16036637] -0.47551090241353305\n",
      "120 [ 0.8850032  0.4655849 -3.7487524] [-0.34694064] -1.6403379580771387\n",
      "140 [ 0.09859236  0.9951279  -4.6197014 ] [0.44980657] -4.301885600197689\n",
      "160 [-0.85694766 -0.5154034   6.9798055 ] [0.49159285] -11.633329626914147\n",
      "180 [-0.62242013 -0.7826833  -6.357145  ] [-0.81554466] -9.073367291695241\n",
      "200 [0.2647891  0.96430635 2.7944098 ] [0.6231875] -2.479742752274073\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBlS9YxYSpJn",
    "ExecuteTime": {
     "end_time": "2025-06-30T11:05:38.482930Z",
     "start_time": "2025-06-30T11:05:38.432390Z"
    }
   },
   "source": [
    "from gymnasium.wrappers import TimeLimit\n",
    "\n",
    "\n",
    "#修改状态\n",
    "class StateStepWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self, env):\n",
    "\n",
    "        #状态空间必须是连续值\n",
    "        assert isinstance(env.observation_space, gym.spaces.Box)\n",
    "\n",
    "        #增加一个新状态字段\n",
    "        low = np.concatenate([env.observation_space.low, [0.0]])\n",
    "        high = np.concatenate([env.observation_space.high, [1.0]])\n",
    "\n",
    "        env.observation_space = gym.spaces.Box(low=low,\n",
    "                                               high=high,\n",
    "                                               dtype=np.float32)\n",
    "\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.step_current = 0\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.step_current = 0\n",
    "        return np.concatenate([self.env.reset(), [0.0]])\n",
    "\n",
    "    def step(self, action):\n",
    "        self.step_current += 1\n",
    "        state, reward, done, truncated, info = self.env.step(action)\n",
    "\n",
    "        #根据step_max修改done\n",
    "        if self.step_current >= 100:\n",
    "            done = True\n",
    "\n",
    "        return self.get_state(state), reward, done, truncated, info\n",
    "\n",
    "    def get_state(self, state):\n",
    "        #添加一个新的state字段\n",
    "        state_step = self.step_current / 100\n",
    "\n",
    "        return np.concatenate([state, [state_step]])\n",
    "\n",
    "\n",
    "test(StateStepWrapper(Pendulum()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StateStepWrapper<Pendulum<TimeLimit<OrderEnforcing<PassiveEnvChecker<PendulumEnv<Pendulum-v1>>>>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11602\\miniconda3\\envs\\RL\\Lib\\site-packages\\gymnasium\\spaces\\box.py:235: UserWarning: \u001B[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001B[0m\n",
      "  gym.logger.warn(\n",
      "C:\\Users\\11602\\miniconda3\\envs\\RL\\Lib\\site-packages\\gymnasium\\spaces\\box.py:305: UserWarning: \u001B[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001B[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 45\u001B[39m\n\u001B[32m     40\u001B[39m         state_step = \u001B[38;5;28mself\u001B[39m.step_current / \u001B[32m100\u001B[39m\n\u001B[32m     42\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m np.concatenate([state, [state_step]])\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m test(StateStepWrapper(Pendulum()))\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 5\u001B[39m, in \u001B[36mtest\u001B[39m\u001B[34m(env, wrap_action_in_list)\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtest\u001B[39m(env, wrap_action_in_list=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m      3\u001B[39m     \u001B[38;5;28mprint\u001B[39m(env)\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m     state = env.reset()\n\u001B[32m      6\u001B[39m     over = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m      7\u001B[39m     step = \u001B[32m0\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 26\u001B[39m, in \u001B[36mStateStepWrapper.reset\u001B[39m\u001B[34m(self, seed, options)\u001B[39m\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mreset\u001B[39m(\u001B[38;5;28mself\u001B[39m, seed=\u001B[38;5;28;01mNone\u001B[39;00m, options=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m     25\u001B[39m     \u001B[38;5;28mself\u001B[39m.step_current = \u001B[32m0\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m np.concatenate([\u001B[38;5;28mself\u001B[39m.env.reset(), [\u001B[32m0.0\u001B[39m]])\n",
      "\u001B[31mValueError\u001B[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8cxnE5bdaQ_3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 919      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.44    |\n",
      "|    explained_variance | -0.00454 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -43.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 976      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 897      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | 4.43e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -28.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 936      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7f94cc7fee80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "#使用Monitor Wrapper,会在训练的过程中输出rollout/ep_len_mean和rollout/ep_rew_mean,就是增加些日志\n",
    "#gym升级到0.26以后失效了,可能是因为使用了自定义的wapper\n",
    "env = DummyVecEnv([lambda: Monitor(Pendulum())])\n",
    "\n",
    "A2C('MlpPolicy', env, verbose=1).learn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zuIcbfv3g9dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<stable_baselines3.common.vec_env.vec_normalize.VecNormalize object at 0x7f949b273e20>\n",
      "0 [[-0.00487219  0.00638567  0.00554428]] [array([1.8279244], dtype=float32)] [-10.]\n",
      "20 [[-0.03349784 -0.66757905 -2.173565  ]] [array([-1.3404763], dtype=float32)] [-0.16482905]\n",
      "40 [[-1.4011567   0.07794451  1.3022798 ]] [array([1.6657785], dtype=float32)] [-0.16956142]\n",
      "60 [[-1.3572015   0.41527337 -1.5391531 ]] [array([1.3103601], dtype=float32)] [-0.12919044]\n",
      "80 [[-0.34073314 -0.9262497   1.2184559 ]] [array([0.99134326], dtype=float32)] [-0.07326685]\n",
      "100 [[ 1.6391766  1.4822493 -1.3587774]] [array([-1.5195391], dtype=float32)] [-0.04477553]\n",
      "120 [[-0.01510759 -1.150826    1.7960454 ]] [array([-0.46556672], dtype=float32)] [-0.07235025]\n",
      "140 [[-0.5499776  -0.83480734 -2.1066453 ]] [array([-0.03180405], dtype=float32)] [-0.08347733]\n",
      "160 [[ 2.0203962  -0.5923113  -0.62100804]] [array([1.302856], dtype=float32)] [-0.00734869]\n",
      "180 [[ 1.8016039   0.8581704  -0.43550822]] [array([1.2153829], dtype=float32)] [-0.00819429]\n",
      "200 [[-1.0306736   0.62731665  2.0643365 ]] [array([-0.90605944], dtype=float32)] [-0.09977578]\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import VecNormalize, VecFrameStack\n",
    "\n",
    "#VecNormalize,他会对state和reward进行Normalize\n",
    "env = DummyVecEnv([Pendulum])\n",
    "env = VecNormalize(env)\n",
    "\n",
    "test(env, wrap_action_in_list=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "2_gym_wrappers_saving_loading.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
